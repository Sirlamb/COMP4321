About this project (Phase 2)
This is a search engine implementation. It consists of 3 main parts: web crawler, retrivel database system, and search engine website.

Crawler: the spider get information from web and generate a database file
etrivel database system: search query and calculate similarity from database
search engine website: the web interface of using the search engine

How to use
The project is based on Python, version 3.10 or above

To run the program, users should do the following.

install the required packages

pip install -r requirements.txt

To execute the program
Down and unzip the folder comp4321
First run webcrawl_final.py to generate a database file
Then run the app.py to use the web interface
